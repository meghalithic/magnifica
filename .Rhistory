traits.melt <- melt(data = df,
id.vars = c("boxID", "zooid.id","imageName", "specimenNR",
"colony.id", "formation", "magnification"),
variable.name = "measurementType",
value.name = "measurementValue")
length(unique(traits.melt$colony.id)) #731 unique colonies [previously 742]
traits.stats <- traits.melt %>%
dplyr::group_by(measurementType) %>%
dplyr::summarise(avg = mean(measurementValue))
traits.stats.form <- traits.melt %>%
dplyr::group_by(measurementType, formation) %>%
dplyr::summarise(avg = mean(measurementValue))
traits.melt.trim <- traits.melt[traits.melt$measurementType %in% traits,]
setwd("~/Library/CloudStorage/Dropbox/Rocks-Paradox/Bryozoans/doi_10.5061_dryad.t4b8gthxm__v2")
---
title: "Reanalyses_Cheetham_dataset"
```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = FALSE)
library(ggplot2)
library(data.table)
library(evolqg)
library(dplyr)
library(nse)
library(grid)
library(gridBase)
library(gridExtra)
library(MCMCglmm)
library(corrplot)
library(MASS)
library(reshape2)
library(scatterplot3d)
library(rgl)
library(scales)
library(RColorBrewer)
library(coin)
in_data<-read.table("chet_dat_rm.txt", header=TRUE,stringsAsFactors = F)
head(in_data)
in_age<-read.table("chet_age.txt", header=TRUE,stringsAsFactors = F)
colnames(in_age)=c("age","COL","SP")
head(in_age)
#Merge data sp by age
indat=merge(in_data,in_age,by="COL")
#Extract unique elements and trait names
colony_list<-unique(in_data$COL)
length(colony_list)
species_list<-unique(in_data$SP)
length(species_list)
traits=names(indat[,4:52])
colNums <- match(c(traits,"COL"),names(indat))
indat=as.data.frame(indat)
Fig <- list ()
for (i in 1:length(traits)){
trt=traits[i]
range_bin=c(min(indat[,3+i],na.rm = T),max(indat[,3+i],na.rm = T))
Fig[[i]] = ggplot(data=indat,aes_string(x=trt,fill="SP.x"))+
geom_histogram(position="identity",binwidth = (range_bin[2]-range_bin[1])/30)+
theme(legend.position="none",text = element_text(size=20))
rm(range_bin)
}
ml <- marrangeGrob(Fig, nrow=7, ncol=7)
ml
trt_lg_N=c("COL","SP.x","age","LZ","WZ","LO","WO","LD","LAVS", "LAVL","NUMA")
dat_lg_N=indat[ intersect(colnames(indat), trt_lg_N)]
head(dat_lg_N)
mean_by_age=setDT(na.omit(dat_lg_N))[, lapply(.SD, mean, na.rm=F), by = .(SP.x,age)]
head(mean_by_age[order(mean_by_age$SP.x)])
colony_means=setDT(na.omit(dat_lg_N))[, lapply(.SD, mean, na.rm=F), by = .(SP.x,COL)]
head(colony_means[order(colony_means$SP.x)])
sp_mean=setDT(na.omit(dat_lg_N))[, lapply(.SD, mean, na.rm=F), by = .(SP.x)]
head(sp_mean[order(sp_mean$SP.x)])
dat_lda=dat_lg_N
dat_lda[,3:10]=scale(dat_lda[,3:10],center=F,scale=T)
data_discriminant=dat_lda
#Selecting the species that are present in Cheetham's Figure for comparison.
data_discriminant=data_discriminant[data_discriminant$SP.x=='auric'|
data_discriminant$SP.x=='lacry'|
data_discriminant$SP.x=='nsp09'|
data_discriminant$SP.x=='nsp10'|
data_discriminant$SP.x=='coll'|
data_discriminant$SP.x=='nsp03'|
data_discriminant$SP.x=='nsp04',]
data_plot=na.omit(data_discriminant[,1:10])
r3 <- lda(formula = SP.x ~ .,
data = data_plot[,2:10], method='mle')
plda = predict(object = r3, # predictions
newdata = data_plot)
prop.lda = r3$svd^2/sum(r3$svd^2) #proportion of the variance explained by each LD axis
dataset = data.frame(species = (data_plot)[,"SP.x"],
lda = plda$x)
p1 <- ggplot(dataset) + geom_point(aes(lda.LD1, lda.LD2, color = species), size = 4) +
labs(x = paste("LD1 (", percent(prop.lda[1]), ")", sep=""),
y = paste("LD2 (", percent(prop.lda[2]), ")", sep=""))
#Preparing the data
colony_SP=split.data.frame(dat_lg_N,dat_lg_N$SP.x)
sample_sizes=lapply(colony_SP,function(x){dim(x)[1]})
enough=as.matrix(sample_sizes)>100
colony_final=colony_SP[names(enough[enough==T,])]
col_data=lapply(colony_final,function(x) x[complete.cases(x),])
#Setting priors for MCMC chain
phen.var=lapply(col_data,function (x){ (cov(x[,3:10]))})
prior=lapply(phen.var, function (x){list(G=list(G1=list(V=x/2,nu=2),
G2=list(V=x/4,nu=2)),
R=list(V=x/4,nu=2))})
#Running the MCMC chain
model_G=list()
trait
traits
help("MCMCglmm")
for (i in 1:length(col_data)){
model_G[[i]]<-MCMCglmm(cbind(LZ,WZ, LO, WO, LD, LAVS, LAVL, NUMA)~trait-1,
random=~us(trait):COL + us(trait):age,
rcov=~us(trait):units,
family=rep("gaussian",8),
data=col_data[[1]],
nitt=15000,thin=10,burnin=5000,
prior=prior[[1]],verbose=TRUE)
}
age
COL
us
col_data
head(col_data)
prior
setwd("~/Documents/GitHub/bryozoa/magnifica/Scripts")
setwd("~/Documents/GitHub/bryozoa/magnifica")
setwd("~/Documents/GitHub/bryozoa/magnifica/")
source("./Scripts/0-env.R")
df <- read.csv("./Results/colonies.traits_1Jul2024.csv",
header = TRUE,
sep = ",",
stringsAsFactors = FALSE)
load(file = "./Results/sum.data.list.RData") #load the g matrices calculated above
mean_by_formation <- sum.data.list[[1]]
mean_by_formation_colony <- sum.data.list[[2]]
means <- sum.data.list[[3]]
mean(mean_by_formation_colony$n.zooid)
zooid_list <- unique(df$zooid.id)
length(zooid_list) #6264 (6658 for 3 zoo)
colony_list <- unique(df$colony.id)
length(colony_list) #599 (711 for 3 zoo)
# arrange formations from oldest to youngest
df$formation <- factor(df$formation, levels = c("NKLS", "NKBS", "Tewkesbury",
"Upper Kai-Iwi",  "Tainui",
"SHCSBSB", "modern"))
formation_list <- unique(df$formation)
length(formation_list) #7
#same order as in df
names(df)
traits = names(df[, c("ln.zh", "ln.mpw.b", "ln.cw.m", "ln.cw.d",
"ln.ow.m", "ln.oh", "ln.c.side", "ln.o.side")])
length(traits) #8
##### TRIM DATASET ----
df.trim <- df %>%
dplyr::select(zooid.id, colony.id, locality, formation, matches(traits))
colNums <- match(c(traits, "zooid.id"), names(df.trim))
df = as.data.frame(df.trim)
p.zh = ggplot(data = df) +
geom_density(aes(x = df[, traits[1]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[1]) +
scale_color_manual(values = col.form)
p.mpw.b = ggplot(data = df) +
geom_density(aes(x = df[, traits[2]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[2]) +
scale_color_manual(values = col.form)
p.cw.m = ggplot(data = df) +
geom_density(aes(x = df[, traits[3]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[3]) +
scale_color_manual(values = col.form)
p.cw.d = ggplot(data = df) +
geom_density(aes(x = df[, traits[4]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[4]) +
scale_color_manual(values = col.form)
p.ow.m = ggplot(data = df) +
geom_density(aes(x = df[, traits[5]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[5]) +
scale_color_manual(values = col.form)
p.oh = ggplot(data = df) +
geom_density(aes(x = df[, traits[6]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[6]) +
scale_color_manual(values = col.form)
p.c.side = ggplot(data = df) +
geom_density(aes(x = df[, traits[7]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[7]) +
scale_color_manual(values = col.form)
p.o.side = ggplot(data = df) +
geom_density(aes(x = df[, traits[8]],
group = formation,
col = formation)) +
plot.theme +
scale_x_continuous(name = traits[8]) +
scale_color_manual(values = col.form)
Fig = list(p.zh, p.mpw.b, p.cw.m, p.cw.d, p.ow.m, p.oh, p.c.side, p.o.side)
ml <- marrangeGrob(Fig, nrow = 4, ncol = 2)
ml
ggsave(ml,
file = "./Results/trait.distribution.png",
width = 14, height = 20, units = "cm")
#### NORMALITY TESTS ----
## shapiro test; but need to subsample to be within 5000
## if significant, then significantly different from normal (i.e., non-normal)
p.vals <- c()
#ln.zh
sub.ln.zh <- sample(df[, traits[1]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.zh)
p.vals[1] <- shapiro.test(sub.ln.zh)$p.value
#ln.mpw.b
sub.ln.mpw.b <- sample(df[, traits[2]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.mpw.b)
p.vals[2] <- shapiro.test(sub.ln.mpw.b)$p.value
#ln.cw.m
sub.ln.cw.m <- sample(df[, traits[3]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.cw.m)
p.vals[3] <- shapiro.test(sub.ln.cw.m)$p.value
#ln.cw.d
sub.ln.cw.d <- sample(df[, traits[4]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.cw.d)
p.vals[4] <- shapiro.test(sub.ln.cw.d)$p.value
#ln.ow.m
sub.ln.ow.m <- sample(df[, traits[5]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.ow.m)
p.vals[5] <- shapiro.test(sub.ln.ow.m)$p.value
#ln.oh
sub.ln.oh <- sample(df[, traits[6]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.oh)
p.vals[6] <- shapiro.test(sub.ln.oh)$p.value
#ln.c.side
sub.ln.c.side <- sample(df[, traits[7]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.c.side)
p.vals[7] <- shapiro.test(sub.ln.c.side)$p.value
#ln.o.side
sub.ln.o.side <- sample(df[, traits[8]],
5000, replace = FALSE, prob = NULL)
shapiro.test(sub.ln.o.side)
p.vals[8] <- shapiro.test(sub.ln.o.side)$p.value
p.vals.df <- as.data.frame(cbind(traits, p.vals))
#by formation
df.norm <- df %>%
dplyr::group_by(formation) %>%
dplyr::summarise(p.val.zh = shapiro.test(ln.zh)$p.value,
p.val.mpw.b = shapiro.test(ln.mpw.b)$p.value,
p.val.cw.m = shapiro.test(ln.cw.m)$p.value,
p.val.cw.d = shapiro.test(ln.cw.d)$p.value,
p.val.ow.m = shapiro.test(ln.ow.m)$p.value,
p.val.oh = shapiro.test(ln.oh)$p.value,
p.val.c.side = shapiro.test(ln.c.side)$p.value,
p.val.o.side = shapiro.test(ln.o.side)$p.value) %>%
as.data.frame()
#### REDUCE TO TRAITS OF INTEREST ----
trt_lg_N = c("formation", "colony.id", "zooid.id", "locality", traits)
dat_lg_N = df[intersect(colnames(df), trt_lg_N)]
head(dat_lg_N) #traits in same order as df and traits
#### CHECK SAMPLE SIZES ----
## number of zooids per colony
range(mean_by_formation_colony$n.zooid)
#5 24 (max 35 for 3 zoo)
#average number of zooids:
mean_by_formation
mean(mean_by_formation$avg.zooid)
sum(mean_by_formation$num.zooid)
sum(mean_by_formation$num.col)
#check number of zooids NOT colonies:
# by colonies use mean_by_formation_colony
# by zooid us dat_lg_N
col_form = split.data.frame(mean_by_formation_colony,  #by colonies
mean_by_formation_colony$formation) #zooids per formation
#just to look; max 328, smallest 19
col_form.n = lapply(col_form, function(x){dim(x)[1]})
#### SPLIT BY FORMATION ----
## by zooids:
by_form = split.data.frame(dat_lg_N,
dat_lg_N$formation)
#just to look; highest 7836, smallest 454
by_form.n = lapply(by_form, function(x){dim(x)[1]})
form_data = lapply(by_form, function(x) x[complete.cases(x),])
#make sampling matrix
form <- levels(formation_list)
col.samp <- c(col_form.n[[1]], col_form.n[[2]], col_form.n[[3]],
col_form.n[[4]], col_form.n[[5]], col_form.n[[6]],
col_form.n[[7]])
zoo.samp <- c(by_form.n[[1]], by_form.n[[2]], by_form.n[[3]],
by_form.n[[4]], by_form.n[[5]], by_form.n[[6]],
by_form.n[[7]])
samp <- as.data.frame(cbind(form, col.samp, zoo.samp))
p.cov = lapply(form_data, function (x){ (cov(x[, 4:11]))}) #traits per colony (not variation within colony)
#### P MATRIX ----
p.cov = lapply(form_data, function (x){ (cov(x[, 4:11]))}) #traits per colony (not variation within colony)
form_data = lapply(by_form, function(x) x[complete.cases(x),])
form_data
#### P MATRIX ----
p.cov = lapply(form_data, function (x){ (cov(x[, 4:11]))}) #traits per colony (not variation within colony)
colnames(form_data)
form_data
form_data[[1]]
#### P MATRIX ----
p.cov = lapply(form_data, function (x){ (cov(x[, 5:12]))}) #traits per colony (not variation within colony)
##### P VARIANCES ----
##Phenotypic variance in traits and eigen vectors
Pmat = p.cov
lapply(Pmat, isSymmetric)  #is.symmetric.matrix
p.variances = lapply(Pmat, diag)
paste("Trait variances")
head(p.variances)
p.eig_variances = lapply(Pmat, function (x) {eigen(x)$values})
# lapply(Pmat, function (x) {eigen(x)})
paste("Eigenvalue variances")
head(p.eig_variances)
p.eig_percent = lapply(p.eig_variances, function (x) {x/sum(x)})
p.eig_per_mat = do.call(rbind, p.eig_percent)
p.eig_per_mat = data.frame(p.eig_per_mat, rownames(p.eig_per_mat))
p.eig_per = melt(p.eig_per_mat)
p.eig_per$rownames.p.eig_per_mat. <- factor(p.eig_per$rownames.p.eig_per_mat.,
levels = c("NKLS", "NKBS", "Tewkesbury",
"Upper Kai-Iwi", "Tainui",
"SHCSBSB", "modern"))
#dev.off()
P_PC_dist = ggplot(p.eig_per,
aes(x = variable, y = value,
group = rownames.p.eig_per_mat.,
colour = rownames.p.eig_per_mat.)) +
geom_line(aes(linetype = rownames.p.eig_per_mat.)) +
geom_point() +
scale_y_continuous("Principal component rank",
limits = c(-.02, 0.7)) +
plot.theme +
theme_linedraw() +
scale_x_discrete("Principal component rank",
labels = c("PC1", "PC2", "PC3", "PC4",
"PC5", "PC6", "PC7", "PC8")) +
scale_color_manual(values = col.form)
P_PC_dist #none negative; none above 1; dim 8 close to 0; could keep 7
P_ext = lapply(Pmat, function (x){ ExtendMatrix(x, ret.dim = 5)$ExtMat}) #to match the G matrix
#ignore warning from above
lapply(P_ext, isSymmetric)
P_Ext_std_variances = lapply(P_ext, diag)
P_Ext_eig_variances = lapply(P_ext, function (x) {eigen(x)$values})
p.comp_mat = RandomSkewers(P_ext) #need at least
p.corr_mat = p.comp_mat$correlations + t(p.comp_mat$correlations)
diag(p.corr_mat) = 1
paste("Random Skewers similarity matrix")
corrplot.mixed(p.corr_mat, upper = "number", lower = "pie")
##### PRIORS -----
#same as p.cov
phen.var = lapply(form_data, function (x){ (cov(x[, 5:12]))}) #traits of ALL; correct for colony later
prior = lapply(phen.var, function (x){list(G = list(G1 = list(V = x/2, nu = 2)),
R = list(V = x/4, nu = 2))})
form.mod <- form_data$modern
phen.var.mod = cov(form.mod[, 5:12]) #traits of ALL; correct for colony later
prior.mod = list(G = list(G1 = list(V = phen.var.mod/2, nu = 2),
G2 = list(V = phen.var.mod/4,nu = 2)),
R = list(V = phen.var.mod/4, nu = 2))
load(file = "./Results/model_G_all.RData") #load the g matrices calculated above
##### POSTERIOR G MATRIX -----
#Retrieving G from posterior
g.model = model_G_all
ntraits = 8
Gmat = lapply(g.model, function (x) {
matrix(posterior.mode(x$VCV)[1:ntraits^2], ntraits, ntraits)})
#label lists as formations
names(Gmat) = names(by_form) #formation_list or form_data
# why aren't traits labeled??
for (i in seq_along(Gmat)){
colnames(Gmat[[i]]) <- traits
}
for (i in seq_along(Gmat)){
rownames(Gmat[[i]]) <- traits
}
diag(Gmat[[2]]) < diag(Pmat[[2]]) # all larger
diag(Gmat[[4]]) < diag(Pmat[[4]]) # all larger
diag(Gmat[[5]]) < diag(Pmat[[5]]) # all larger
##### G VARIANCES -----
lapply(Gmat, isSymmetric)  #is.symmetric.matrix
g.variances = lapply(Gmat, diag)
paste("Trait variances")
head(g.variances)
##### G EIGEN -----
g.eig_variances = lapply(Gmat, function (x) {eigen(x)$values})
paste("Eigenvalue variances")
head(g.eig_variances)
g.eig_percent = lapply(g.eig_variances, function (x) {x/sum(x)})
g.eig_per_mat = do.call(rbind, g.eig_percent)
g.eig_per_mat = data.frame(g.eig_per_mat, rownames(g.eig_per_mat))
g.eig_per = melt(g.eig_per_mat)
g.eig_per$rownames.g.eig_per_mat. <- factor(g.eig_per$rownames.g.eig_per_mat.,
levels = c("NKLS", "NKBS", "Tewkesbury",
"Upper Kai-Iwi", "Tainui",
"SHCSBSB", "modern"))
#dev.off()
G_PC_dist = ggplot(g.eig_per,
aes(x = variable, y = value,
group = rownames.g.eig_per_mat.,
colour = rownames.g.eig_per_mat.)) +
geom_line(aes(linetype = rownames.g.eig_per_mat.)) +
geom_point() +
plot.theme +
theme_linedraw() +
scale_x_discrete("Principal component rank",
labels = c("PC1", "PC2", "PC3", "PC4",
"PC5", "PC6", "PC7", "PC8")) +
scale_y_continuous("%Variation in the PC",
limits = c(-.02, 0.7)) +
scale_color_manual(values = col.form)
G_PC_dist
G_ext = lapply(Gmat, function (x){ ExtendMatrix(x, ret.dim = 5)$ExtMat}) #not 8 because last eigen value (#6) was negative
#ignore warning from above
lapply(G_ext, isSymmetric)
Ext_std_variances = lapply(G_ext, diag)
Ext_eig_variances = lapply(G_ext, function (x) {eigen(x)$values})
##need to create random cov.m for comparison
#cov.m <- RandomMatrix(8, 1, 1, 100)
#G_list <- list(G_ext)
g.comp_mat = RandomSkewers(G_ext) #need at least
g.corr_mat = g.comp_mat$correlations + t(g.comp_mat$correlations)
diag(g.corr_mat) = 1
paste("Random Skewers similarity matrix")
corrplot.mixed(g.corr_mat,upper = "number", lower = "pie")
# We start by generating "individuals" (i.e., colonies)
# in a population with VCV patterns corresponding to a known G.
# We then calculate VCV matrices for those individuals and obtain their
# similarity with the 'true' G.
repititions <- 200
#Defining the population size. Each population size is repeated 200 times.
#Starting at 2 individuals and going up to 100,
col_form.n # max 328, min 19
pop.size = sort(rep(c(2:500), repititions)) #make 500 so much bigger than max no. colonies
pop.dist <- lapply(pop.size, function (x){mvrnorm(n = x,
rep(0,8), # mean 0 for 8 traits
G_ext[[1]])}) # Simulate individual trait data based on the first VCOV matrix in our time series and different sample sizes.
pop.dist
G_ext[[1]]
pop.size
pop.dist <- lapply(pop.size, function (x){mvrnorm(n = x,
rep(0,8), # mean 0 for 8 traits
G_ext[[1]])}) # Simulate individual trait data based on the first VCOV matrix in our time series and different sample sizes.
# Calculate VCOV matrices
pop.cv <- lapply(pop.dist, cov)
# Estimate selection gradients based on Random Skewers, comparing our true
# G matrix and the undersampled pooled P matrix.
RS_result = RandomSkewers(pop.cv,
G_ext[[1]])
out_results <- cbind(RS_result$correlation, pop.size)
# Computing Random Skewers between pairs of actual G matrices in our data
#(n = 7 for 7 formations)
# sub-setting so that we only analyze the traits and formation of interest
mean.df.sub <- mean_by_formation_colony[, c(1, 4, 6, 8, 10, 12, 14, 16, 18)]
#remove rows with NA so that the sample size gets correct when we plot
#the sample size for the VCOV.
mean.df_complete_cases <- mean.df.sub[complete.cases(mean.df.sub), ] #remove rows with NA so that the sample size gets correct when we plot the sample size for the VCOV.
# Calculating the sample size for each time point
colony_samples = split.data.frame(mean.df_complete_cases, mean.df_complete_cases$formation) #Sample size
sample_sizes_G = lapply(colony_samples, function(x){dim(x)[1]})
comp_sampleN = matrix(0, 7, 7) #calculating the smallest sample size in the comparison among pairs of G for length of formation
for (i in 1:length(sample_sizes_G)){
for (j in 1:length(sample_sizes_G)){
comp_sampleN[i,j] = min(as.numeric(sample_sizes_G[i]), as.numeric(sample_sizes_G[j]))
}
}
comp_sampleN
# Here, we do the actual Random Skewers test and
# combined the results (correlations in the response to selection)
# with the smallest sample size for the pairs of G that are investigated
comp_mat = RandomSkewers(G_ext)
melt_comp = melt(comp_mat$correlations[lower.tri(comp_mat$correlations)])
melt_samples = melt(comp_sampleN[lower.tri(comp_sampleN)])
obs_melt = cbind(melt_comp, melt_samples)
colnames(obs_melt) = c("RS","N")
#Plotting the result
plot(out_results[, 2], out_results[, 1],
xlab = "Sample size", ylab = "Similarity",
pch = 19, col = "grey", cex = .5)
points(obs_melt$N, obs_melt$RS,
col = "#00BFC4", pch = 19, cex = .5)
p.rare <- ggplot() +
geom_point(aes(out_results[, 2], out_results[, 1]),
pch = 19, col = "grey", size = 2) +
geom_point(aes(obs_melt$N, obs_melt$RS),
col = "#00BFC4", pch = 19, size = 2) +
plot.theme +
scale_x_continuous(name = "Sample size") +
scale_y_continuous(name = "Similarity")
p.rare
ggsave(p.rare,
file = "./Results/rarefaction.png",
width = 14, height = 10, units = "cm")
